#!/usr/bin/env python3
"""
Quick test to verify AI model detection appears in output formats
"""

import json
import sys
sys.path.insert(0, '/home/gene/Wave-2-2025-Methodology/SPOT_News')

from format_renderer import FormatRenderer

# Sample narrative components with AI detection data
narrative_components = {
    'lede': 'Test policy document scores B+ (82.9/100)',
    'grade': 'B+',
    'score': 82.9,
    'ai_detection': {
        'ai_detection_score': 0.532,
        'confidence': 0.72,
        'likely_ai_model': {
            'model': 'Cohere',
            'confidence': 1.0,
            'analysis': 'High confidence that content was generated by Cohere',
            'model_scores': {
                'Ollama/Llama': 0.70,
                'Google Gemini': 0.35,
                'Claude (Anthropic)': 0.53,
                'Mistral AI': 0.80,
                'Cohere': 1.0
            }
        }
    },
    'trust_score': {'trust_score': 61.7},
    'risk_tier': {
        'risk_tier': 'MEDIUM',
        'risk_score': 52.0,
        'required_controls': ['LOGGING', 'BIAS_AUDIT', 'EXPLAINABILITY']
    }
}

narrative_text = "Test narrative for policy document."

renderer = FormatRenderer()

print("=" * 70)
print("X THREAD OUTPUT:")
print("=" * 70)
x_thread = renderer.render(narrative_text, 'x_thread', narrative_components)
print(x_thread)
print("\n")

print("=" * 70)
print("LINKEDIN OUTPUT (last 300 chars):")
print("=" * 70)
linkedin = renderer.render(narrative_text, 'linkedin', narrative_components)
print(linkedin[-300:])
