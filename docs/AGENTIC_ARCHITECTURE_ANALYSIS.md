# Agentic vs. Pipeline Architecture for Sparrow SPOT Scaleâ„¢

**Document Version:** 1.0  
**Date:** November 27, 2025  
**Status:** Strategic Analysis  
**Decision:** Hybrid Approach Recommended  

---

## Executive Summary

**Question:** Should Sparrow SPOT Scaleâ„¢ adopt an agentic (AI agent-based) architecture?

**Answer:** No for core grading; Yes for specialized enhancement tasks.

**Recommendation:** Maintain the current deterministic pipeline for transparency scoring, and add optional agentic agents for high-value verification tasks (citation checking, fact validation, external data retrieval).

**Rationale:** 
- Core grading requires reproducibility, auditability, and trust
- Agentic enhancement can add value for research-heavy tasks without compromising foundation
- Hybrid approach enables tiered pricing (basic pipeline vs. premium with agents)

---

## Current Architecture Analysis

### Pipeline-Based System (v8.3)

**Architecture:**
```
Input Document
    â†“
AI Detection Engine (6 levels)
    â†“
Statistical Analyzer
    â†“
Article/Policy Analyzer
    â†“
Criteria Scoring (SPARROW/SPOT-Policy)
    â†“
Grade Calculation
    â†“
Output Generation (JSON, HTML, Narratives, Certificates)
```

**Processing Model:**
- Sequential, deterministic pipeline
- Rule-based scoring with fixed rubrics
- Statistical methods for AI detection
- Optional LLM usage (Ollama) for narrative generation only
- No LLM involvement in scoring decisions

**Performance Characteristics:**
- **Speed:** 30-60 seconds per document
- **Cost:** ~$0 per analysis (local processing)
- **Reproducibility:** 100% - same input always produces same output
- **Explainability:** Full audit trail of score calculations
- **Scalability:** Limited by CPU, not API quotas

---

## Strengths of Current Pipeline Approach

### 1. Reproducibility & Auditability âœ…
**Why It Matters:**
- Government accountability use cases require consistent scoring
- Legal defensibility depends on deterministic results
- Academic validation requires replicable methodology
- Regulatory compliance (NIST AI RMF) needs documented decision logic

**Example:**
```
Bill C-9 analyzed on Nov 1, 2025: 82/100 (B+)
Same bill analyzed on Nov 27, 2025: 82/100 (B+)
âœ“ Identical scores prove system integrity
```

**With Agentic:**
```
Bill C-9 analyzed on Nov 1: 82/100
Same bill analyzed on Nov 27: 79/100
âœ— Why the difference? LLM updated? Prompt drift? Data changed?
```

### 2. Trust & Transparency âœ…
**Why It Matters:**
- Users need to understand *why* a document scored as it did
- Black-box AI scoring undermines credibility
- Your brand is built on transparency - scoring must model this

**Current System:**
```
Fiscal Transparency: 85/100
  â”œâ”€ Revenue breakdown present: +25
  â”œâ”€ Expenditure detail: +30
  â”œâ”€ Assumption documentation: +20
  â””â”€ Risk disclosure: +10
âœ“ Every point is traceable to specific evidence
```

**Agentic System:**
```
Fiscal Transparency: 85/100
  â””â”€ "The AI agent determined this score based on holistic analysis"
âœ— User cannot verify or challenge the reasoning
```

### 3. Speed & Cost Efficiency âœ…
**Why It Matters:**
- Free tier requires zero marginal cost
- Real-time grading needs sub-minute performance
- High-volume use cases (API customers) need predictable costs

**Current System:**
- 1,000 documents/day = $0 in API costs
- Processing time: ~45 seconds average
- Bottleneck: CPU/RAM, which scales cheaply

**Agentic System:**
- 1,000 documents/day = $100-500 in LLM API costs
- Processing time: 2-5 minutes with multiple agent calls
- Bottleneck: API rate limits and costs

### 4. Regulatory Compliance âœ…
**Why It Matters:**
- NIST AI RMF requires explainable AI
- Government procurement needs auditable systems
- Academic institutions require methodological rigor

**Current System:**
- NIST AI 600-1 compliant (deterministic scoring)
- Full documentation of decision logic
- No "AI risk" in core grading (only in detection layer)

**Agentic System:**
- NIST compliance challenged (LLM as decision-maker)
- Requires additional AI governance framework
- Introduces model bias risks to scoring

---

## Weaknesses of Current Pipeline Approach

### 1. Cannot Verify External Facts âŒ
**Problem:**
- Document claims "Study published in Nature 2024" - pipeline cannot verify
- Citation exists, but is it accurate? Accessible? Supporting the claim?
- Financial figures stated - are they in EDGAR filings?

**Impact:**
- Limits depth of analysis
- Requires manual fact-checking for high-stakes use cases
- Misses retracted citations, broken links, fabricated sources

### 2. No Contextual Adaptation âŒ
**Problem:**
- Every document scored with same rigid rubric
- Cannot adjust for document subtype nuances
- Emerging document types (AI-human hybrid) not handled optimally

**Example:**
- Preprint vs. peer-reviewed paper - current system treats same
- Annual report vs. 10-K filing - criteria weights don't adapt
- Bill vs. Budget - both use SPOT-Policy, but emphasis differs

### 3. Limited Research Capabilities âŒ
**Problem:**
- Cannot automatically look up author credibility
- Cannot cross-reference claims against knowledge bases
- Cannot check if cited studies support the claims made

**Impact:**
- Misses sophisticated misinformation (accurate citations used out of context)
- Cannot detect "citation padding" (real sources, but irrelevant)
- Requires expert review for validation

### 4. No Multi-Document Synthesis âŒ
**Problem:**
- Each document analyzed in isolation
- Cannot compare to similar documents for anomaly detection
- Cannot track claims across document versions

**Example:**
- Budget 2024 promised X, Budget 2025 mentions Y - are they consistent?
- Company's 2023 ESG report claimed A, 2024 report now silent on A
- Current system cannot flag these contradictions automatically

---

## Agentic Architecture: What It Enables

### Agent Types for Document Analysis

#### 1. Research Agent ðŸ”
**Capabilities:**
- Web search for document context
- Author/organization credibility lookup
- Historical document comparison
- Related document discovery

**Example Task:**
```
Input: "Analyze this academic paper"
Agent Actions:
  1. Look up author h-index on Google Scholar
  2. Check institution reputation rankings
  3. Find related papers by same author
  4. Identify author's conflict of interest disclosures
Output: Context report for scoring adjustment
```

**Value Add:** Provides background that humans would manually research

---

#### 2. Citation Validator Agent ðŸ“š
**Capabilities:**
- Verify citations exist and are accessible
- Check if citation supports the claim made
- Detect retracted papers (Retraction Watch API)
- Validate DOI/PMID/ArXiv links

**Example Task:**
```
Input: Paper cites "Smith et al. 2020, Nature"
Agent Actions:
  1. Query CrossRef API for DOI
  2. Check if paper was retracted
  3. Retrieve abstract/conclusion
  4. Assess if cited text supports claim
  5. Check citation count (via Semantic Scholar)
Output: Citation quality score + red flags
```

**Value Add:** Automates tedious manual verification, catches fraud

---

#### 3. Fact-Checking Agent âœ“
**Capabilities:**
- Extract factual claims from document
- Search trusted sources for verification
- Cross-reference numerical data
- Identify contradictions with known facts

**Example Task:**
```
Input: "Canada's GDP grew 3.2% in 2024"
Agent Actions:
  1. Query Statistics Canada API
  2. Compare stated figure to official data
  3. Check date ranges match
  4. Flag discrepancies
Output: Verified/Disputed/Unverifiable + evidence
```

**Value Add:** Catches factual errors that rule-based systems miss

---

#### 4. Financial Validator Agent ðŸ’°
**Capabilities:**
- Pull data from EDGAR/SEDAR filings
- Verify reported financials match filings
- Calculate ratios for consistency checks
- Compare to peer companies

**Example Task:**
```
Input: "Our revenue grew 50% to $100M"
Agent Actions:
  1. Retrieve company's 10-K from EDGAR
  2. Extract revenue figures
  3. Calculate actual growth rate
  4. Compare to prior year and peer group
  5. Check for restatements
Output: Financial accuracy score + discrepancies
```

**Value Add:** Automates forensic accounting tasks

---

#### 5. Legal Precedent Agent âš–ï¸
**Capabilities:**
- Shepardize/KeyCite legal citations
- Verify cases are still good law
- Check jurisdiction matches
- Validate statutory references

**Example Task:**
```
Input: Brief cites "Roe v. Wade, 410 U.S. 113 (1973)"
Agent Actions:
  1. Query Westlaw API (or free alternative)
  2. Check if case overruled (yes, in 2022)
  3. Identify treatment history
  4. Flag as bad law
Output: Citation status + alternative precedents
```

**Value Add:** Prevents reliance on overruled precedents, catches malpractice

---

#### 6. Quality Control Agent ðŸŽ¯
**Capabilities:**
- Review the review for consistency
- Compare to similar documents
- Detect scoring anomalies
- Flag edge cases for human review

**Example Task:**
```
Input: Document scored 74.8/100 (C+)
Agent Actions:
  1. Compare to 100 similar documents
  2. Check if score is outlier
  3. Review criteria scores for contradictions
  4. Assess confidence in AI detection
  5. Identify ambiguous sections
Output: Confidence score + human review trigger
```

**Value Add:** Meta-analysis catches scoring errors and edge cases

---

## Hybrid Architecture Recommendation

### Three-Layer System

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 1: DETERMINISTIC CORE (Always Runs)                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ AI Detection (6 levels) - Statistical methods            â”‚
â”‚  â€¢ Criteria Scoring - Rule-based rubrics                    â”‚
â”‚  â€¢ Grade Calculation - Fixed algorithms                     â”‚
â”‚  â€¢ NIST Compliance - Deterministic checks                   â”‚
â”‚                                                              â”‚
â”‚  OUTPUT: Base transparency score (0-100) + grade            â”‚
â”‚  COST: $0 | TIME: 30-60s | REPRODUCIBILITY: 100%           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 2: AGENTIC ENHANCEMENT (Optional - Premium)          â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Citation Validator Agent (SCHOLAR variant)               â”‚
â”‚  â€¢ Fact-Checking Agent (all variants)                       â”‚
â”‚  â€¢ Financial Validator Agent (CORPORATE variant)            â”‚
â”‚  â€¢ Legal Precedent Agent (LEGAL variant)                    â”‚
â”‚  â€¢ Research Agent (context gathering)                       â”‚
â”‚                                                              â”‚
â”‚  OUTPUT: Verification scores + confidence intervals + flags â”‚
â”‚  COST: $0.10-0.50 | TIME: +60-120s | VALUE: External data  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  LAYER 3: SYNTHESIS & REPORTING (Hybrid)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â€¢ Combine deterministic scores (Layer 1)                   â”‚
â”‚  â€¢ Augment with agent findings (Layer 2)                    â”‚
â”‚  â€¢ Calculate confidence intervals                           â”‚
â”‚  â€¢ Trigger human review if needed                           â”‚
â”‚  â€¢ Generate enhanced narrative                              â”‚
â”‚                                                              â”‚
â”‚  OUTPUT: Comprehensive report with validation + confidence  â”‚
â”‚  COST: Included | TIME: +10s | VALUE: Full transparency     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Implementation Strategy

### Phase 1: Foundation (Current) âœ…
**Timeline:** Complete  
**Focus:** Deterministic pipeline for SPARROW & SPOT-Policy  
**Status:** Shipped in v8.3

**Deliverables:**
- âœ… 6-level AI detection
- âœ… Dual-variant system (journalism + policy)
- âœ… NIST compliance framework
- âœ… Web interface + API
- âœ… Multiple output formats

---

### Phase 2: First Agent (Months 3-6) ðŸŽ¯
**Timeline:** Q2 2026  
**Focus:** Citation Validator Agent for SCHOLAR variant  
**Trigger:** After SCHOLAR variant launched

**Deliverables:**
- Citation Validator Agent
  - CrossRef/PubMed API integration
  - Retraction Watch database check
  - DOI validation
  - Citation-claim alignment scoring
- Premium tier pricing ($0.25/paper extra)
- A/B testing with academic users
- Validation study showing improved accuracy

**Success Metrics:**
- Catches 90%+ of retracted citations
- Reduces manual fact-checking time by 60%
- 20%+ of SCHOLAR users upgrade to premium

---

### Phase 3: Fact-Checking Agent (Months 6-12) ðŸ”
**Timeline:** Q3-Q4 2026  
**Focus:** General fact-checking for all variants  
**Trigger:** After 1,000+ premium users

**Deliverables:**
- Fact-Checking Agent
  - Web search integration
  - Statistical database queries (Stats Canada, BLS, etc.)
  - Claim extraction from documents
  - Verification report generation
- Mid-tier pricing ($0.15/document)
- Integration with all variants
- Confidence scoring system

**Success Metrics:**
- Identifies 70%+ of factual errors
- 95%+ precision (low false positives)
- Featured in academic journal or major media

---

### Phase 4: Variant-Specific Agents (Year 2) ðŸ¢
**Timeline:** 2027  
**Focus:** Financial & Legal specialized agents  
**Trigger:** CORPORATE and LEGAL variants launched

**Deliverables:**
- Financial Validator Agent
  - EDGAR/SEDAR scraper
  - Financial ratio calculator
  - Peer comparison engine
  - Accounting rule validator
- Legal Precedent Agent
  - Case law database integration
  - Citation status checker
  - Jurisdiction validator
  - Malpractice risk scoring

**Success Metrics:**
- Enterprise customer adoption (50+ companies)
- Integration with Bloomberg/LexisNexis
- Featured in WSJ or ABA Journal

---

### Phase 5: Full Agentic Suite (Year 3+) ðŸš€
**Timeline:** 2028+  
**Focus:** Multi-agent orchestration  
**Trigger:** 10,000+ active users

**Deliverables:**
- Quality Control Agent (meta-reviewer)
- Research Agent (context gathering)
- Multi-document synthesis
- Temporal analysis (track changes over time)
- Anomaly detection across corpus
- Enterprise agent customization

**Success Metrics:**
- 100,000+ documents analyzed/month
- 30%+ conversion to enterprise tier
- API revenue exceeds $1M/year

---

## Pricing Strategy: Tiered by Agent Usage

### Free Tier
**Features:**
- Deterministic pipeline only (Layer 1)
- AI detection + basic grading
- JSON/HTML output
- 10 documents/month

**Cost to User:** $0  
**Cost to Provide:** $0  
**Purpose:** Lead generation, education, open access

---

### Basic Tier ($9.99/month)
**Features:**
- All Free tier features
- 100 documents/month
- Narrative generation (Ollama)
- Certificate generation
- Priority processing

**Cost to User:** $9.99/month  
**Cost to Provide:** ~$0.50/month  
**Purpose:** Individual power users, freelancers

---

### Premium Tier ($49/month)
**Features:**
- All Basic tier features
- **Citation Validator Agent** (SCHOLAR)
- **Fact-Checking Agent** (all variants)
- Confidence intervals
- 500 documents/month
- API access (limited)

**Cost to User:** $49/month  
**Cost to Provide:** ~$75-150/month in LLM costs  
**Purpose:** Academics, journalists, consultants  
**Note:** Profitable at scale (500 docs Ã— $0.25 = $125 value)

---

### Professional Tier ($199/month)
**Features:**
- All Premium tier features
- **All variant-specific agents**
- Multi-document analysis
- Temporal tracking
- 2,000 documents/month
- Full API access
- White-label reports

**Cost to User:** $199/month  
**Cost to Provide:** ~$300-600/month  
**Purpose:** Small teams, consultancies, newsrooms

---

### Enterprise Tier (Custom Pricing)
**Features:**
- Unlimited documents
- Custom agent development
- On-premise deployment option
- Dedicated support
- SLA guarantees
- Integration with customer systems

**Cost to User:** $5,000-50,000/year  
**Cost to Provide:** Variable (mostly support/dev time)  
**Purpose:** Governments, universities, corporations, law firms

---

## Technical Implementation Details

### Agent Framework Selection

**Option 1: LangGraph (Recommended)**
- Part of LangChain ecosystem
- Built for complex agent workflows
- Supports state management
- Good observability/debugging
- Open source

**Option 2: Microsoft AutoGen**
- Multi-agent conversation framework
- Good for research-heavy tasks
- Strong community
- Integrates with Azure

**Option 3: CrewAI**
- Role-based agents
- Simpler API than LangGraph
- Good for well-defined tasks
- Growing ecosystem

**Recommendation:** Start with **LangGraph** for flexibility, migrate to custom framework if needed at scale.

---

### Agent Orchestration Patterns

#### Pattern 1: Sequential (Simple)
```python
# For straightforward verification tasks
result_1 = citation_agent.run(document)
result_2 = fact_checker.run(document, result_1)
result_3 = synthesizer.run(result_1, result_2)
```

**Use for:** Citation validation, fact-checking  
**Pros:** Simple, predictable  
**Cons:** Slower (agents run one at a time)

---

#### Pattern 2: Parallel (Efficient)
```python
# For independent verification tasks
results = await asyncio.gather(
    citation_agent.run(document),
    fact_checker.run(document),
    financial_agent.run(document)
)
synthesis = synthesizer.run(results)
```

**Use for:** Multi-agent analysis  
**Pros:** Fast (agents run concurrently)  
**Cons:** Higher API costs (parallel calls)

---

#### Pattern 3: Hierarchical (Complex)
```python
# Supervisor agent coordinates sub-agents
supervisor = SupervisorAgent([
    citation_agent,
    fact_checker,
    financial_agent
])
result = supervisor.run(document, criteria="SCHOLAR")
```

**Use for:** Complex multi-step analysis  
**Pros:** Adaptive (supervisor decides which agents to call)  
**Cons:** Adds LLM overhead for coordination

---

### LLM Selection for Agents

**Citation Validator:** GPT-4o-mini or Claude Haiku  
- Needs: Good reasoning, API access  
- Cost: $0.02-0.05/request  

**Fact-Checker:** GPT-4o or Claude Sonnet  
- Needs: Web search, high accuracy  
- Cost: $0.10-0.20/request  

**Financial Validator:** GPT-4o (with structured outputs)  
- Needs: Mathematical reasoning, data extraction  
- Cost: $0.05-0.15/request  

**Quality Control:** Claude Opus or GPT-4  
- Needs: Meta-reasoning, high reliability  
- Cost: $0.20-0.50/request  

**Total cost per document (all agents):** $0.39-1.00  
**Revenue target (Premium tier):** $0.49+ per document  
**Margin:** Profitable at >500 docs/month

---

## Risk Analysis

### Risks of Adding Agents

#### 1. Cost Unpredictability ðŸ’¸
**Risk:** LLM API costs could spike unexpectedly  
**Impact:** Negative margins, need to raise prices  
**Mitigation:**
- Set hard limits on API calls per document
- Cache agent results for repeated analyses
- Use cheaper models for simple tasks
- Implement cost monitoring/alerts

---

#### 2. Reproducibility Loss ðŸ”„
**Risk:** Same document gets different scores on different runs  
**Impact:** User trust erodes, regulatory compliance challenged  
**Mitigation:**
- Keep deterministic score as primary
- Agent results are "enhancements" not replacements
- Version lock LLM models
- Document all agent decisions

---

#### 3. Hallucination Errors ðŸ¤–
**Risk:** Agent fabricates facts or citations  
**Impact:** False positives in fact-checking, credibility damage  
**Mitigation:**
- Always verify agent claims against ground truth
- Human review for high-stakes decisions
- Confidence scoring on all agent outputs
- Clear disclaimers about AI limitations

---

#### 4. Latency Increases â±ï¸
**Risk:** 2-5 minute processing times unacceptable for users  
**Impact:** User abandonment, poor experience  
**Mitigation:**
- Parallel agent execution
- Async processing (email results)
- Progressive disclosure (show base score first)
- Streaming results (update UI as agents complete)

---

#### 5. Complexity Burden ðŸ”§
**Risk:** System becomes hard to maintain/debug  
**Impact:** Development velocity slows, bugs multiply  
**Mitigation:**
- Modular agent design (easy to add/remove)
- Comprehensive logging/observability
- A/B testing before full rollout
- Keep option to disable agents per-user

---

### Risks of NOT Adding Agents

#### 1. Competitive Disadvantage ðŸ“‰
**Risk:** Competitors build agentic systems first  
**Impact:** Perceived as "old tech," lose market share  
**Assessment:** Medium risk - few competitors in transparency scoring niche

---

#### 2. Limited Depth ðŸŽ¯
**Risk:** Cannot match human expert analysis quality  
**Impact:** Enterprise customers require human review, won't pay premium  
**Assessment:** High risk - agents could enable higher price points

---

#### 3. Scalability Constraints ðŸ“Š
**Risk:** Manual fact-checking doesn't scale to 100K docs/month  
**Impact:** Revenue ceiling, must hire humans for verification  
**Assessment:** Medium risk - can hire contractors, but margins suffer

---

## Decision Framework: When to Use Agents

### Use Agents When: âœ…

1. **Task requires external data retrieval**
   - Citation verification needs API calls
   - Financial data needs EDGAR scraping
   - Fact-checking needs web search

2. **High-value, low-volume use case**
   - Enterprise customers willing to pay
   - Mission-critical analysis justifies cost
   - Human expert review would otherwise be needed

3. **User opts in explicitly**
   - Premium tier feature
   - User acknowledges longer processing time
   - User accepts cost

4. **Output is enhancement, not replacement**
   - Deterministic score remains primary
   - Agent findings add context
   - Clear separation in UI/reporting

---

### Don't Use Agents When: âŒ

1. **Core transparency grading**
   - Reproducibility required
   - Auditability mandated
   - Speed is critical

2. **Free/basic tier users**
   - Cannot justify cost
   - Latency unacceptable
   - Value not demonstrated

3. **Task is algorithmic**
   - Readability scoring - use formula
   - Citation counting - use regex
   - Statistical analysis - use numpy

4. **Ground truth is unavailable**
   - Agent would just speculate
   - No way to verify claims
   - Hallucination risk too high

---

## Proof of Concept: Citation Validator Agent

### Prototype Specification

**Goal:** Validate citations in academic papers (SCHOLAR variant)

**Input:** 
- Document text (parsed PDF/HTML)
- Extracted citations (bibliography)
- Claims that reference citations

**Agent Workflow:**
```
1. Extract citations from document
   â””â”€ Use regex + ML model to parse references

2. For each citation (sample 10 random):
   a. Query CrossRef API for DOI/metadata
   b. Check Retraction Watch for retraction status
   c. Verify URL accessibility (if provided)
   d. Extract abstract/conclusion (if available)
   e. Compare claim to citation content (LLM task)

3. Calculate citation quality score:
   - Accessibility: % of citations with working links
   - Validity: % not retracted or corrected
   - Relevance: % where citation supports claim
   - Recency: Average age of citations
   - Diversity: % primary sources vs. reviews

4. Flag high-risk issues:
   - Retracted citations (critical)
   - Inaccessible citations (medium)
   - Irrelevant citations (low)
   - Predatory journals (medium)
```

**Output:**
```json
{
  "citation_quality_score": 78,
  "total_citations": 42,
  "sampled_citations": 10,
  "accessible": 8,
  "retracted": 1,
  "relevant": 7,
  "average_age_years": 5.2,
  "primary_source_ratio": 0.6,
  "flags": [
    {
      "type": "retracted",
      "citation": "Smith et al. 2019",
      "reason": "Retracted March 2021 for data fabrication",
      "severity": "critical"
    }
  ],
  "confidence": 0.85,
  "processing_time_seconds": 45,
  "api_cost_usd": 0.23
}
```

**Integration:**
```python
# In SCHOLAR variant grading
base_score = deterministic_pipeline(document)  # 0-100

if user.tier >= "premium":
    citation_validation = citation_agent.run(document)
    
    # Adjust CQ (Citation Quality) criterion based on agent findings
    if citation_validation["retracted"] > 0:
        cq_penalty = min(20, citation_validation["retracted"] * 5)
        base_score["CQ"] -= cq_penalty
        base_score["flags"].append("Retracted citations detected")
    
    # Add validation report to output
    base_score["citation_validation"] = citation_validation

return base_score
```

**Success Criteria:**
- Identifies 95%+ of retracted citations
- Processing time <60 seconds
- Cost <$0.30 per paper
- False positive rate <5%

---

## Conclusion

### Final Recommendation: Hybrid Architecture

**Keep:**
- âœ… Deterministic pipeline for core grading
- âœ… Rule-based transparency scoring
- âœ… Statistical AI detection
- âœ… Fast, cheap, reproducible foundation

**Add:**
- âœ… Citation Validator Agent (SCHOLAR variant, Q2 2026)
- âœ… Fact-Checking Agent (all variants, Q4 2026)
- âœ… Variant-specific agents (CORPORATE, LEGAL, 2027+)
- âœ… Premium pricing tier for agent features

**Avoid:**
- âŒ Replacing deterministic scoring with LLM decisions
- âŒ Using agents for tasks that algorithms handle well
- âŒ Forcing agent usage on free/basic tier users
- âŒ Sacrificing reproducibility for "smarter" AI

---

### Implementation Timeline

| Quarter | Focus | Deliverable |
|---------|-------|-------------|
| Q1 2026 | SCHOLAR variant | Deterministic grading for academic papers |
| Q2 2026 | Citation Agent | First agentic enhancement (premium tier) |
| Q3 2026 | Fact-Checker | General verification agent (mid-tier) |
| Q4 2026 | Validation | Academic study proving agent value |
| Q1 2027 | CORPORATE variant | Financial validator agent |
| Q2 2027 | LEGAL variant | Legal precedent agent |
| Q3 2027 | Multi-agent | Orchestration + Quality Control agent |
| Q4 2027 | Enterprise | Custom agents for large customers |

---

### Success Metrics (Year 1 of Agents)

**Technical:**
- Citation validator accuracy: >95%
- Processing time increase: <2 minutes
- Cost per analysis: <$0.50
- Uptime/reliability: >99%

**Business:**
- Premium tier conversion: >15%
- Customer satisfaction: >4.5/5
- Agent-enabled revenue: >$50K
- Enterprise pilots: >3 customers

**Impact:**
- Detected fraud cases: >10 documented
- Academic partnerships: >5 universities
- Media coverage: >3 major publications
- Validation studies: >1 peer-reviewed paper

---

**Document End**

*This analysis supports a phased approach to agentic enhancement, preserving the core strengths of Sparrow SPOT Scaleâ„¢ while adding high-value AI agent capabilities for premium users.*
